
@article{kokciyan_applying_2021,
	title = {Applying {Metalevel} {Argumentation} {Frameworks} to {Support} {Medical} {Decision} {Making}},
	volume = {36},
	issn = {1941-1294},
	doi = {10.1109/MIS.2021.3051420},
	abstract = {People are increasingly employing artificial intelligence as the basis for decision-support systems (DSSs) to assist them in making well-informed decisions. Adoption of DSS is challenging when such systems lack support, or evidence, for justifying their recommendations. DSSs are widely applied in the medical domain, due to the complexity of the domain and the sheer volume of data that render manual processing difficult. This article proposes a metalevel argumentation-based decision-support system that can reason with heterogeneous data (e.g., body measurements, electronic health records, clinical guidelines), while incorporating the preferences of the human beneficiaries of those decisions. The system constructs template-based explanations for the recommendations that it makes. The proposed framework has been implemented in a system to support stroke patients and its functionality has been tested in a pilot study. User feedback shows that the system can run effectively over an extended period.},
	number = {2},
	journal = {IEEE Intelligent Systems},
	author = {Kökciyan, Nadin and Sassoon, Isabel and Sklar, Elizabeth and Modgil, Sanjay and Parsons, Simon},
	month = mar,
	year = {2021},
	note = {Conference Name: IEEE Intelligent Systems},
	keywords = {Intelligent systems, Artificial intelligence, Complexity theory, Computational argumentation, Decision making, decision-support systems, Electronic medical records, explainability, healthcare, Hypertension, Medical services, Spread spectrum communication, Stakeholders},
	pages = {64--71},
}

@inproceedings{sassoon_explainable_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Explainable {Argumentation} for {Wellness} {Consultation}},
	isbn = {978-3-030-30391-4},
	doi = {10.1007/978-3-030-30391-4_11},
	abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers’ intuition of what constitutes a ‘good’ explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
	language = {en},
	booktitle = {Explainable, {Transparent} {Autonomous} {Agents} and {Multi}-{Agent} {Systems}},
	publisher = {Springer International Publishing},
	author = {Sassoon, Isabel and Kökciyan, Nadin and Sklar, Elizabeth and Parsons, Simon},
	editor = {Calvaresi, Davide and Najjar, Amro and Schumacher, Michael and Främling, Kary},
	year = {2019},
	keywords = {Explainability, Explainable AI, Explanation, Interpretability, Transparency},
	pages = {186--202},
}

@article{kociyan_collaborative_2019,
	title = {A {Collaborative} {Decision} {Support} {Tool} for {Managing} {Chronic} {Conditions}},
	url = {https://ebooks.iospress.nl/doi/10.3233/SHTI190302},
	doi = {10.3233/SHTI190302},
	urldate = {2022-01-18},
	journal = {MEDINFO 2019: Health and Wellbeing e-Networks for All},
	author = {Köciyan, Nadin and Chapman, Martin and Balatsoukas, Panagiotis and Sassoon, Isabel and Essers, Kai and Ashworth, Mark and Curcin, Vasa and Modgil, Sanjay and Parsons, Simon and Sklar, Elizabeth I.},
	year = {2019},
	note = {Publisher: IOS Press},
	pages = {644--648},
}

@article{kokciyan_argumentation-based_2020,
	title = {An {Argumentation}-{Based} {Approach} to {Generate} {Domain}-{Specific} {Explanations}},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-66412-1_20},
	doi = {10.1007/978-3-030-66412-1_20},
	abstract = {In argumentation theory, argument schemes are constructs to generalise common patterns of reasoning; whereas critical questions (CQs) capture the reasons why argument schemes might not generate...},
	language = {en},
	urldate = {2022-01-18},
	journal = {Multi-Agent Systems and Agreement Technologies},
	author = {Kökciyan, Nadin and Parsons, Simon and Sassoon, Isabel and Sklar, Elizabeth and Modgil, Sanjay},
	month = apr,
	year = {2020},
	note = {Publisher: Springer, Cham},
	pages = {319--337},
}
